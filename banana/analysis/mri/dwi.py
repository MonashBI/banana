import os
from logging import getLogger
import tempfile
import subprocess as sp
from nipype.interfaces.utility import Merge, IdentityInterface
from nipype.interfaces.fsl import (
    TOPUP, ApplyTOPUP, BET, FUGUE, Merge as FslMerge)
from nipype.interfaces.utility import Merge as merge_lists
from nipype.interfaces.fsl.epi import PrepareFieldmap, EddyQuad  # , EddySquad
from nipype.interfaces.mrtrix3 import ResponseSD, Tractography
from nipype.interfaces.mrtrix3.utils import BrainMask, TensorMetrics
from nipype.interfaces.mrtrix3.reconst import (
    FitTensor, ConstrainedSphericalDeconvolution)
# from nipype.workflows.dwi.fsl.tbss import create_tbss_all
# from banana.interfaces.noddi import (
#     CreateROI, BatchNODDIFitting, SaveParamsAsNIfTI)
from nipype.interfaces import fsl, mrtrix3, utility
from arcana.utils.interfaces import MergeTuple, Chain
from arcana.data import FilesetSpec, InputFilesetSpec
from arcana.utils.interfaces import SelectSession
from arcana.analysis import ParamSpec, SwitchSpec
from arcana.exceptions import ArcanaMissingDataException, ArcanaNameError
from arcana.data.file_format import pdf_format
from banana.interfaces.motion_correction import GenTopupConfigFiles
from banana.interfaces.mrtrix import (
    DWIPreproc, MRCat, ExtractDWIorB0, MRMath, DWIBiasCorrect, DWIDenoise,
    MRCalc, DWIIntensityNorm, AverageResponse, DWI2Mask, MergeFslGrads)
from banana.requirement import (
    fsl_req, mrtrix_req, ants_req)
from banana.interfaces.mrtrix import MRConvert, ExtractFSLGradients
from banana.analysis import AnalysisMetaClass
from banana.interfaces.motion_correction import (
    PrepareDWI, AffineMatrixGeneration)
from banana.interfaces.dwi import TransformGradients, SelectShell
from banana.interfaces.utility import AppendPath
from banana.analysis.base import Analysis
from banana.bids_ import BidsInputs, BidsAssocInputs
from banana.exceptions import BananaUsageError
from banana.citation import (
    mrtrix_cite, fsl_cite, eddy_cite, topup_cite, distort_correct_cite,
    n4_cite, dwidenoise_cites, eddy_repol_cite)
from banana.file_format import (
    mrtrix_image_format, nifti_gz_format, nifti_gz_x_format, fsl_bvecs_format,
    fsl_bvals_format, text_format, dicom_format, eddy_par_format,
    mrtrix_track_format, motion_mats_format, text_matrix_format,
    directory_format, csv_format, zip_format, STD_IMAGE_FORMATS, json_format)
from .base import MriAnalysis
from .epi import EpiSeriesAnalysis, EpiAnalysis

logger = getLogger('banana')


class DwiAnalysis(EpiSeriesAnalysis, metaclass=AnalysisMetaClass):

    desc = "Diffusion-weighted MRI contrast"

    add_data_specs = [
        InputFilesetSpec('anat_5tt', mrtrix_image_format,
                         desc=("A co-registered segmentation image taken from "
                               "freesurfer output and simplified into 5 tissue"
                               " types. Used in ACT streamlines tractography"),
                         optional=True),
        InputFilesetSpec('anat_fs_recon_all', zip_format, optional=True,
                         desc=("Co-registered freesurfer recon-all output. "
                               "Used in building the connectome")),
        InputFilesetSpec('reverse_phase', STD_IMAGE_FORMATS, optional=True),
        FilesetSpec('grad_dirs', fsl_bvecs_format, 'preprocess_pipeline'),
        FilesetSpec('grad_dirs_coreg', fsl_bvecs_format,
                    'series_coreg_pipeline',
                    desc=("The gradient directions coregistered to the "
                          "orientation of the coreg reference")),
        FilesetSpec('bvalues', fsl_bvals_format, 'preprocess_pipeline',
                    desc=("")),
        FilesetSpec('eddy_par', eddy_par_format, 'preprocess_pipeline',
                    desc=("Parameters used by Eddy preprocessing tool")),
        FilesetSpec('eddy_qc', zip_format, 'preprocess_pipeline',
                    desc=("QC output generated by Eddy preprocessing tool")),
        FilesetSpec('eddy_qc_summary', json_format, 'eddy_qc_summary_pipeline',
                    desc=("Study-wise database containing quality metrics and "
                          "data info."), frequency='per_visit'),
        FilesetSpec('eddy_qc_report', pdf_format, 'eddy_qc_summary_pipeline',
                    desc=("Study-wise database containing quality metrics and "
                          "data info."), frequency='per_visit'),
        FilesetSpec('noise_residual', mrtrix_image_format,
                    'preprocess_pipeline',
                    desc=("")),
        FilesetSpec('tensor', nifti_gz_format, 'tensor_pipeline',
                    desc=("")),
        FilesetSpec('tensor_residual', nifti_gz_format,
                    'residual_pipeline',
                    desc=("The residual signal after the tensor has been "
                          "fit to the signal")),
        FilesetSpec('fa', nifti_gz_format, 'tensor_metrics_pipeline',
                    desc=("")),
        FilesetSpec('adc', nifti_gz_format, 'tensor_metrics_pipeline',
                    desc=("")),
        FilesetSpec('wm_response', text_format, 'response_pipeline',
                    desc=("")),
        FilesetSpec('gm_response', text_format, 'response_pipeline',
                    desc=("")),
        FilesetSpec('csf_response', text_format, 'response_pipeline',
                    desc=("")),
        FilesetSpec('avg_response', text_format, 'average_response_pipeline',
                    desc=("")),
        FilesetSpec('wm_odf', mrtrix_image_format, 'fod_pipeline',
                    desc=("")),
        FilesetSpec('gm_odf', mrtrix_image_format, 'fod_pipeline',
                    desc=("")),
        FilesetSpec('csf_odf', mrtrix_image_format, 'fod_pipeline',
                    desc=("")),
        FilesetSpec('norm_intensity', mrtrix_image_format,
                    'intensity_normalisation_pipeline',
                    desc=("")),
        FilesetSpec('norm_intens_fa_template', mrtrix_image_format,
                    'intensity_normalisation_pipeline', frequency='per_dataset',
                    desc=("")),
        FilesetSpec('norm_intens_wm_mask', mrtrix_image_format,
                    'intensity_normalisation_pipeline', frequency='per_dataset',
                    desc=("")),
        FilesetSpec('global_tracks', mrtrix_track_format,
                    'global_tracking_pipeline',
                    desc=("")),
        FilesetSpec('wm_mask', mrtrix_image_format,
                    'global_tracking_pipeline',
                    desc=("")),
        FilesetSpec('connectome', csv_format, 'connectome_pipeline',
                    desc=(""))]

    add_param_specs = [
        ParamSpec('pe_dir', None, dtype=str,
                  desc=("Phase-encoding direction of DW series")),
        ParamSpec('intra_moco_parts', 0, dtype=int,
                  desc=("Number of partitions within a volume to motion "
                        "correct w.r.t the volume. If == 0, intra-volume MoCo "
                        "is disabled. Intra-volume MoCo requires slice timings"
                        " to be found in 'series' header")),
        SwitchSpec('eddy_moco_by_suscep', False,
                   desc="Use susceptibility to determine motion correction"),
        SwitchSpec('force_shelled', False,
                   desc=("Force eddy to treat gradient encoding scheme as "
                         "being shelled")),
        ParamSpec('eddy_model', 'none',
                  choices=('none', 'linear', 'quadratic'),
                  desc=("Model for how diffusion gradients generate eddy "
                        "currents.")),
        ParamSpec('tbss_skel_thresh', 0.2,
                  desc=("")),
        ParamSpec('fsl_mask_f', 0.25,
                  desc=("")),
        ParamSpec('bet_robust', True,
                  desc=("")),
        ParamSpec('bet_f_threshold', 0.2,
                  desc=("")),
        ParamSpec('bet_reduce_bias', False,
                  desc=("")),
        ParamSpec('num_global_tracks', int(1e9),
                  desc=("")),
        ParamSpec('global_tracks_cutoff', 0.05,
                  desc=("")),
        SwitchSpec('preproc_denoise', False,
                   desc=("")),
        SwitchSpec('response_algorithm', 'tax',
                   ('tax', 'dhollander', 'msmt_5tt'),
                   desc=("")),
        ParamSpec('num_shells', None, desc=('Number of b-value shells')),
        MriAnalysis.param_spec('bet_method').with_new_choices('mrtrix'),
        SwitchSpec('reorient2std', False,
                   desc=(""))]

    primary_bids_input = BidsInputs(
        spec_name='series', type='dwi',
        valid_formats=(nifti_gz_x_format, nifti_gz_format))

    default_bids_inputs = [primary_bids_input,
                           BidsAssocInputs(
                               spec_name='bvalues',
                               primary=primary_bids_input,
                               association='grads',
                               type='bval',
                               format=fsl_bvals_format),
                           BidsAssocInputs(
                               spec_name='grad_dirs',
                               primary=primary_bids_input,
                               association='grads',
                               type='bvec',
                               format=fsl_bvecs_format),
                           BidsAssocInputs(
                               spec_name='reverse_phase',
                               primary=primary_bids_input,
                               association='epi',
                               format=nifti_gz_format,
                               drop_if_missing=True)]

    RECOMMENDED_NUM_SESSIONS_FOR_INTENS_NORM = 5

    primary_scan_name = 'series'

    def b_shells(self):
        bpaths = []
        if 'bvalues' in self.input_names:
            bpaths = [f.path for f in self.spec('bvalues').slice]
        elif 'series' in self.input_names:
            mrtrix_ver = self.environment.satisfy(mrtrix_req.v(3.0))
            tmp_dir = tempfile.mkdtemp()
            self.environment.load(mrtrix_ver)
            try:
                bpaths = []
                for fileset in self.spec('series').slice:
                    bpath = os.path.join(
                        tmp_dir, '{}__{}'.format(fileset.subject_id,
                                                    fileset.visit_id))
                    try:
                        sp.check_call(
                            ('mrconvert {} {} -export_grad_fsl {} {}'
                                .format(fileset.path,
                                        bpath + '.mif', bpath + '.bvec',
                                        bpath + '.bval')), shell=True)
                    except sp.CalledProcessError as e:
                        logger.error(
                            ("Could not extract bvalues from series file "
                                "'%s'"), fileset.path)
                        raise e
                    bpaths.append(bpath + '.bval')
            finally:
                self.environment.unload(mrtrix_ver)
        else:
            raise BananaUsageError(
                "b-values not provided to study, required to determine "
                "number of shells")
        bvalues = set()
        for bpath in bpaths:
            with open(bpath) as f:
                bvalues.update(round(float(b), -1)
                                for b in f.read().split())
        return sorted(bvalues)

    @property
    def multi_tissue(self):
        return self.branch('response_algorithm',
                           ('msmt_5tt', 'dhollander'))

    @property
    def fod_algorithm(self):
        if self.parameter('response_algorithm') == 'msmt_5tt':
            algorithm = 'msmt_csd'
        else:
            algorithm = 'csd'
        return algorithm

    def fsl_grads(self, pipeline, coregistered=True):
        "Adds and returns a node to the pipeline to merge the FSL grads and "
        "bvecs"
        try:
            grad_fsl = pipeline.node('grad_fsl')
        except ArcanaNameError:
            if self.is_coregistered and coregistered:
                grad_dirs = 'grad_dirs_coreg'
            else:
                grad_dirs = 'grad_dirs'
            # Gradient merge node
            grad_fsl = pipeline.add(
                "grad_fsl",
                MergeFslGrads(),
                inputs={
                    'grad_dirs': (grad_dirs, fsl_bvecs_format),
                    'bvals': ('bvalues', fsl_bvals_format)})
        return (grad_fsl, 'out')

    def extract_magnitude_pipeline(self, **name_maps):

        pipeline = self.new_pipeline(
            'extract_magnitude',
            desc="Extracts the first b==0 volume from the series",
            citations=[],
            name_maps=name_maps)

        dwiextract = pipeline.add(
            'dwiextract',
            ExtractDWIorB0(
                bzero=True,
                out_ext='.nii.gz'),
            inputs={
                'in_file': ('series', nifti_gz_format),
                'grad_fsl': self.fsl_grads(pipeline, coregistered=False)},
            requirements=[mrtrix_req.v('3.0rc3')])

        pipeline.add(
            "extract_first_vol",
            MRConvert(
                coord=(3, 0),
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'in_file': (dwiextract, 'out_file')},
            outputs={
                'magnitude': ('out_file', nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        return pipeline

    def preprocess_pipeline(self, **name_maps):
        """
        Performs a series of FSL preprocessing steps, including Eddy and Topup

        Parameters
        ----------
        phase_dir : str{AP|LR|IS}
            The phase encode direction
        """

        # Determine whether we can correct for distortion, i.e. if reference
        # scans are provided
        # Include all references
        references = [fsl_cite, eddy_cite, topup_cite, eddy_repol_cite,
                      distort_correct_cite, n4_cite]
        if self.branch('preproc_denoise'):
            references.extend(dwidenoise_cites)

        pipeline = self.new_pipeline(
            name='preprocess',
            name_maps=name_maps,
            desc=(
                "Preprocess dMRI studies using distortion correction"),
            citations=references)

        dw_series = ('series', mrtrix_image_format)

        # Denoise the dwi-scan
        if self.branch('preproc_denoise'):
            # Run denoising
            denoise = pipeline.add(
                'denoise',
                DWIDenoise(
                    nthreads=(self.processor.cpus_per_task
                              if self.processor.cpus_per_task else 0)),
                inputs={
                    'in_file': dw_series},
                requirements=[mrtrix_req.v('3.0rc3')])

            # Calculate residual noise
            subtract_operands = pipeline.add(
                'subtract_operands',
                Merge(2),
                inputs={
                    'in1': dw_series,
                    'in2': (denoise, 'noise')})

            pipeline.add(
                'subtract',
                MRCalc(
                    operation='subtract',
                    nthreads=(self.processor.cpus_per_task
                              if self.processor.cpus_per_task else 0)),
                inputs={
                    'operands': (subtract_operands, 'out')},
                outputs={
                    'noise_residual': ('out_file', mrtrix_image_format)},
                requirements=[mrtrix_req.v('3.0rc3')])

            denoised = (denoise, 'out_file')
        else:
            denoised = dw_series

        # Preproc kwargs
        preproc_inputs = {'in_file': denoised}
        preproc_kwargs = {}

        if self.provided('grad_dirs') and self.provided('bvalues'):
            # Gradient merge node
            grad_fsl = pipeline.add(
                "grad_fsl",
                MergeFslGrads(),
                inputs={
                    'grad_dirs': ('grad_dirs', fsl_bvecs_format),
                    'bvals': ('bvalues', fsl_bvals_format)})

            preproc_inputs['grad_fsl'] = (grad_fsl, 'out')

        elif self.spec('series').format not in (dicom_format,
                                                mrtrix_image_format):
            raise BananaUsageError(
                "Either input 'series' image needs to gradient directions and "
                "b-values in its header or they need to be explicitly "
                "provided to 'grad_dirs' and 'bvalues' {}".format(self))

        if self.provided('reverse_phase'):

            if self.provided('magnitude', default_okay=False):
                dwi_reference = ('magnitude', mrtrix_image_format)
            else:
                # Extract b=0 volumes
                dwiextract = pipeline.add(
                    'dwiextract',
                    ExtractDWIorB0(
                        bzero=True,
                        out_ext='.mif'),
                    inputs=preproc_inputs,
                    requirements=[mrtrix_req.v('3.0rc3')])

                # Get first b=0 from dwi b=0 volumes
                extract_first_b0 = pipeline.add(
                    "extract_first_vol",
                    MRConvert(
                        coord=(3, 0),
                        nthreads=(self.processor.cpus_per_task
                                  if self.processor.cpus_per_task else 0)),
                    inputs={
                        'in_file': (dwiextract, 'out_file')},
                    requirements=[mrtrix_req.v('3.0rc3')])

                dwi_reference = (extract_first_b0, 'out_file')

            merge_rphase = pipeline.add(
                'merge_rphase',
                Merge(2),
                inputs={
                    'in1': dwi_reference,
                    'in2': ('reverse_phase', mrtrix_image_format)})

            # Concatenate extracted forward rpe with reverse rpe
            combined_images = pipeline.add(
                'combined_images',
                MRCat(
                    nthreads=(self.processor.cpus_per_task
                              if self.processor.cpus_per_task else 0),
                    axis=3),
                inputs={
                    'input_files': (merge_rphase, 'out')},
                requirements=[mrtrix_req.v('3.0rc3')])

            # Create node to extract the phase-encoding direction
            # prep_dwi = pipeline.add(
            #     'prepare_dwi',
            #     PrepareDWI(),
            #     inputs={
            #         'pe_dir': ('ped', float),
            #         'ped_polarity': ('pe_angle', float)})

            preproc_kwargs['rpe_pair'] = True

            # distortion_correction = True
            preproc_inputs['se_epi'] = (combined_images, 'out_file')
        else:
            # distortion_correction = False
            preproc_kwargs['rpe_none'] = True

        if self.parameter('pe_dir') is not None:
            preproc_kwargs['pe_dir'] = self.parameter('pe_dir')

        eddy_parameters = '--repol --cnr_maps  --slm={}'.format(
            self.parameter('eddy_model'))
        if self.parameter('intra_moco_parts') > 0:
            eddy_parameters += ' --mporder={}'.format(
                self.parameter('intra_moco_parts'))
        if self.branch('eddy_moco_by_suscep'):
            eddy_parameters += ' --estimate_move_by_susceptibility'
        if self.branch('force_shelled'):
            eddy_parameters += ' --data_is_shelled '

        preproc = pipeline.add(
            'dwipreproc',
            DWIPreproc(
                no_clean_up=True,
                out_file_ext='.mif',
                eddy_parameters=eddy_parameters,
                eddyqc_all='qc-all',
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0),
                **preproc_kwargs),
            inputs=preproc_inputs,
            outputs={
                'eddy_par': ('eddy_parameters', eddy_par_format),
                'eddy_qc': ('eddyqc_all', directory_format)},
            requirements=[mrtrix_req.v('3.0rc3'), fsl_req.v('6.0.1')],
            wall_time=60)

        # if distortion_correction:
        #     pipeline.connect(prep_dwi, 'pe', preproc, 'pe_dir')

        mask = pipeline.add(
            'dwi2mask',
            BrainMask(
                out_file='brainmask.mif',
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'in_file': (preproc, 'out_file')},
            requirements=[mrtrix_req.v('3.0rc3')])

        # Create bias correct node
        bias_correct = pipeline.add(
            "bias_correct",
            DWIBiasCorrect(
                algorithm='ants'),
            inputs={
                'in_file': (preproc, 'out_file'),
                'mask': (mask, 'out_file')},
            outputs={
                'series_preproc': ('out_file', mrtrix_image_format)},
            requirements=[mrtrix_req.v('3.0rc3'), ants_req.v('2.0')])

        # Extract gradient directions that have been motion-corrected
        # by dwipreproc
        pipeline.add(
            "extract_moco_grad",
            ExtractFSLGradients(),
            inputs={
                'in_file': (bias_correct, 'out_file')},
            outputs={
                'grad_dirs': ('bvecs_file', fsl_bvecs_format),
                'bvalues': ('bvals_file', fsl_bvals_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        # Create node to reorient preproc out_file
        if self.branch('reorient2std'):
            raise NotImplementedError(
                "Reorientation to standard isn't handle at this stage because "
                "gradients would also need to be rotated accordingly by a "
                "bespoke interface")
            # reorient = pipeline.add(
            #     'fslreorient2std',
            #     fsl.utils.Reorient2Std(
            #         output_type='NIFTI_GZ'),
            #     inputs={
            #         'in_file': ('series', nifti_gz_format)},
            #     requirements=[fsl_req.v('5.0.9')])
            # reoriented = (reorient, 'out_file')
        else:
            pass
            # reoriented = ('series', nifti_gz_format)

        return pipeline

    def eddy_qc_summary_pipeline(self, **name_maps):

        pipeline = self.new_pipeline(
            name='eddy_qc_summary',
            name_maps=name_maps,
            desc=("Run group-wise analysis of Eddy QC output"))

        pipeline.add(
            'eddy_squad',
            EddySquad(),
            inputs={
                'quad_dirs': ('eddy_qc', directory_format)},
            outputs={
                'eddy_qc_summary': ('group_db_json', json_format),
                'eddy_qc_report': ('group_qc_pdf', pdf_format)},
            requirements=[fsl_req.v('5.0.11')],
            joinfield=['quad_dirs'],
            joinsource=self.SUBJECT_ID)

        return pipeline

    def brain_extraction_pipeline(self, **name_maps):
        """
        Generates a whole brain mask using MRtrix's 'dwi2mask' command

        Parameters
        ----------
        mask_tool: Str
            Can be either 'bet' or 'dwi2mask' depending on which mask tool you
            want to use
        """

        if self.branch('bet_method', 'mrtrix'):
            pipeline = self.new_pipeline(
                'brain_extraction',
                desc="Generate brain mask from b0 images",
                citations=[mrtrix_cite],
                name_maps=name_maps)

            if self.provided('coreg_ref'):
                series = 'series_coreg'
            else:
                series = 'series_preproc'

            # Create mask node
            masker = pipeline.add(
                'dwi2mask',
                BrainMask(
                    out_file='brain_mask.nii.gz',
                    nthreads=(self.processor.cpus_per_task
                              if self.processor.cpus_per_task else 0)),
                inputs={
                    'in_file': (series, nifti_gz_format),
                    'grad_fsl': self.fsl_grads(pipeline, coregistered=False)},
                outputs={
                    'brain_mask': ('out_file', nifti_gz_format)},
                requirements=[mrtrix_req.v('3.0rc3')])

            merge = pipeline.add(
                'merge_operands',
                Merge(2),
                inputs={
                    'in1': ('mag_preproc', nifti_gz_format),
                    'in2': (masker, 'out_file')})

            pipeline.add(
                'apply_mask',
                MRCalc(
                    operation='multiply',
                    nthreads=(self.processor.cpus_per_task
                              if self.processor.cpus_per_task else 0)),
                inputs={
                    'operands': (merge, 'out')},
                outputs={
                    'brain': ('out_file', nifti_gz_format)},
                requirements=[mrtrix_req.v('3.0rc3')])
        else:
            pipeline = super().brain_extraction_pipeline(**name_maps)
        return pipeline

    def series_coreg_pipeline(self, **name_maps):

        pipeline = super().series_coreg_pipeline(**name_maps)

        # Apply coregistration transform to gradients
        pipeline.add(
            'transform_grads',
            TransformGradients(),
            inputs={
                'gradients': ('grad_dirs', fsl_bvecs_format),
                'transform': ('coreg_fsl_mat', text_matrix_format)},
            outputs={
                'grad_dirs_coreg': ('transformed', fsl_bvecs_format)})

        return pipeline

    def intensity_normalisation_pipeline(self, **name_maps):

        if self.num_sessions < 2:
            raise ArcanaMissingDataException(
                "Cannot normalise intensities of DWI images as analysis only "
                "contains a single session")
        elif self.num_sessions < self.RECOMMENDED_NUM_SESSIONS_FOR_INTENS_NORM:
            logger.warning(
                "The number of sessions in the analysis ({}) is less than the "
                "recommended number for intensity normalisation ({}). The "
                "results may be unreliable".format(
                    self.num_sessions,
                    self.RECOMMENDED_NUM_SESSIONS_FOR_INTENS_NORM))

        pipeline = self.new_pipeline(
            name='intensity_normalization',
            desc="Corrects for B1 field inhomogeneity",
            citations=[mrtrix_req.v('3.0rc3')],
            name_maps=name_maps)

        mrconvert = pipeline.add(
            'mrconvert',
            MRConvert(
                out_ext='.mif',
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'in_file': (self.series_preproc_spec_name, nifti_gz_format),
                'grad_fsl': self.fsl_grads(pipeline)},
            requirements=[mrtrix_req.v('3.0rc3')])

        # Pair subject and visit ids together, expanding so they can be
        # joined and chained together
        session_ids = pipeline.add(
            'session_ids',
            utility.IdentityInterface(
                ['subject_id', 'visit_id']),
            inputs={
                'subject_id': (Analysis.SUBJECT_ID, int),
                'visit_id': (Analysis.VISIT_ID, int)})

        # Set up join nodes
        join_fields = ['dwis', 'masks', 'subject_ids', 'visit_ids']
        join_over_subjects = pipeline.add(
            'join_over_subjects',
            utility.IdentityInterface(
                join_fields),
            inputs={
                'masks': (self.brain_mask_spec_name, nifti_gz_format),
                'dwis': (mrconvert, 'out_file'),
                'subject_ids': (session_ids, 'subject_id'),
                'visit_ids': (session_ids, 'visit_id')},
            joinsource=self.SUBJECT_ID,
            joinfield=join_fields)

        join_over_visits = pipeline.add(
            'join_over_visits',
            Chain(
                join_fields),
            inputs={
                'dwis': (join_over_subjects, 'dwis'),
                'masks': (join_over_subjects, 'masks'),
                'subject_ids': (join_over_subjects, 'subject_ids'),
                'visit_ids': (join_over_subjects, 'visit_ids')},
            joinsource=self.VISIT_ID,
            joinfield=join_fields)

        # Intensity normalization
        intensity_norm = pipeline.add(
            'dwiintensitynorm',
            DWIIntensityNorm(
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'in_files': (join_over_visits, 'dwis'),
                'masks': (join_over_visits, 'masks')},
            outputs={
                'norm_intens_fa_template': ('fa_template',
                                            mrtrix_image_format),
                'norm_intens_wm_mask': ('wm_mask', mrtrix_image_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        # Set up expand nodes
        pipeline.add(
            'expand', SelectSession(),
            inputs={
                'subject_ids': (join_over_visits, 'subject_ids'),
                'visit_ids': (join_over_visits, 'visit_ids'),
                'inlist': (intensity_norm, 'out_files'),
                'subject_id': (Analysis.SUBJECT_ID, int),
                'visit_id': (Analysis.VISIT_ID, int)},
            outputs={
                'norm_intensity': ('item', mrtrix_image_format)})

        # Connect inputs
        return pipeline

    def tensor_pipeline(self, **name_maps):
        """
        Fits the apparrent diffusion tensor (DT) to each voxel of the image
        """

        pipeline = self.new_pipeline(
            name='tensor',
            desc=("Estimates the apparent diffusion tensor in each "
                  "voxel"),
            citations=[],
            name_maps=name_maps)

        # Create tensor fit node
        pipeline.add(
            'dwi2tensor',
            FitTensor(
                out_file='dti.nii.gz',
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0),
                predicted_signal='predicted.mif'),
            inputs={
                'grad_fsl': self.fsl_grads(pipeline),
                'in_file': (self.series_preproc_spec_name, nifti_gz_format),
                'in_mask': (self.brain_mask_spec_name, nifti_gz_format)},
            outputs={
                'tensor': ('out_file', nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        return pipeline

    def residual_pipeline(self, **name_maps):
        """
        Fits the apparrent diffusion tensor (DT) to each voxel of the image
        """

        pipeline = self.new_pipeline(
            name='residuals',
            desc=("Calculates the residuals after fitting tensor to each "
                  "shell"),
            citations=[],
            name_maps=name_maps)

        b_shells = set(self.b_shells())
        b_shells.remove(0.0)

        iterate_shells = pipeline.add(
            'iterate_shells',
            IdentityInterface(
                fields=['b']))
        iterate_shells.iterables = ('b', b_shells)

        select_shell = pipeline.add(
            'select_shell',
            SelectShell(
                tol=5.0),
            inputs={
                'target': (iterate_shells, 'b'),
                'bvals': ('bvalues', fsl_bvals_format)})

        merge0 = pipeline.add(
            'merge_axis_n_indices',
            MergeTuple(2),
            inputs={
                'in2': (select_shell, 'indices')})
        merge0.inputs.in1 = 3

        split_shells = pipeline.add(
            'split_shells',
            MRConvert(
                out_ext='.mif'),
            inputs={
                'in_file': (self.series_preproc_spec_name, nifti_gz_format),
                'grad_fsl': self.fsl_grads(pipeline),
                'coord': (merge0, 'out')},
            requirements=[mrtrix_req.v('3.0')])

        # Create tensor fit node
        tensor = pipeline.add(
            'dwi2tensor',
            FitTensor(
                out_file='dti.nii.gz',
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0),
                predicted_signal='predicted.mif'),
            inputs={
                'in_file': (split_shells, 'out_file'),
                'in_mask': (self.brain_mask_spec_name, nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0')])

        merge1 = pipeline.add(
            'merge_tensor_predicted',
            Merge(2),
            inputs={
                'in1': (split_shells, 'out_file'),
                'in2': (tensor, 'predicted_signal')})

        residual = pipeline.add(
            'residual',
            MRCalc(
                operation='subtract'),
            inputs={
                'operands': (merge1, 'out')})

        max_residual = pipeline.add(
            'max_residual',
            MRMath(
                operation='max',
                axis=3),
            inputs={
                'in_files': (residual, 'out_file')})

        merge3 = pipeline.add(
            'merge_operands3',
            Merge(2),
            inputs={
                'in1': (max_residual, 'out_file'),
                'in2': (self.brain_mask_spec_name, nifti_gz_format)})

        mask = pipeline.add(
            'apply_mask',
            MRCalc(
                operation='multiply',
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'operands': (merge3, 'out')},
            requirements=[mrtrix_req.v('3.0rc3')])

        pipeline.add(
            'merge_dims',
            MRCat(
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0),
                axis=3),
            inputs={
                'input_scans': (mask, 'out_file')},
            outputs={
                'tensor_residual': ('out_file', mrtrix_image_format)},
            joinsource='iterate_shells',
            joinfield=['input_scans'],
            requirements=[mrtrix_req.v('3.0rc3')])

        return pipeline

    def tensor_metrics_pipeline(self, **name_maps):
        """
        Fits the apparrent diffusion tensor (DT) to each voxel of the image
        """

        pipeline = self.new_pipeline(
            name='fa',
            desc=("Calculates the FA and ADC from a tensor image"),
            citations=[],
            name_maps=name_maps)

        # Create tensor fit node
        pipeline.add(
            'metrics',
            TensorMetrics(
                out_fa='fa.nii.gz',
                out_adc='adc.nii.gz'),
            inputs={
                'in_file': ('tensor', nifti_gz_format),
                'in_mask': (self.brain_mask_spec_name, nifti_gz_format)},
            outputs={
                'fa': ('out_fa', nifti_gz_format),
                'adc': ('out_adc', nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        return pipeline

    def response_pipeline(self, **name_maps):
        """
        Estimates the fibre orientation distribution (FOD) using constrained
        spherical deconvolution

        Parameters
        ----------
        response_algorithm : str
            Algorithm used to estimate the response
        """

        pipeline = self.new_pipeline(
            name='response',
            desc=("Estimates the fibre response function"),
            citations=[mrtrix_cite],
            name_maps=name_maps)

        # Create fod fit node
        response = pipeline.add(
            'response',
            ResponseSD(
                algorithm=self.parameter('response_algorithm'),
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'grad_fsl': self.fsl_grads(pipeline),
                'in_file': (self.series_preproc_spec_name, nifti_gz_format),
                'in_mask': (self.brain_mask_spec_name, nifti_gz_format)},
            outputs={
                'wm_response': ('wm_file', text_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        # Connect to outputs
        if self.multi_tissue:
            response.inputs.gm_file = 'gm.txt',
            response.inputs.csf_file = 'csf.txt',
            pipeline.connect_output('gm_response', response, 'gm_file',
                                    text_format)
            pipeline.connect_output('csf_response', response, 'csf_file',
                                    text_format)

        return pipeline

    def average_response_pipeline(self, **name_maps):
        """
        Averages the estimate response function over all subjects in the
        project
        """

        pipeline = self.new_pipeline(
            name='average_response',
            desc=(
                "Averages the fibre response function over the project"),
            citations=[mrtrix_cite],
            name_maps=name_maps)

        join_subjects = pipeline.add(
            'join_subjects',
            utility.IdentityInterface(['responses']),
            inputs={
                'responses': ('wm_response', text_format)},
            outputs={},
            joinsource=self.SUBJECT_ID,
            joinfield=['responses'])

        join_visits = pipeline.add(
            'join_visits',
            Chain(['responses']),
            inputs={
                'responses': (join_subjects, 'responses')},
            joinsource=self.VISIT_ID,
            joinfield=['responses'])

        pipeline.add(
            'avg_response',
            AverageResponse(
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'in_files': (join_visits, 'responses')},
            outputs={
                'avg_response': ('out_file', text_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        return pipeline

    def fod_pipeline(self, **name_maps):
        """
        Estimates the fibre orientation distribution (FOD) using constrained
        spherical deconvolution

        Parameters
        ----------
        """

        pipeline = self.new_pipeline(
            name='fod',
            desc=("Estimates the fibre orientation distribution in each"
                  " voxel"),
            citations=[mrtrix_cite],
            name_maps=name_maps)

        # Create fod fit node
        dwi2fod = pipeline.add(
            'dwi2fod',
            ConstrainedSphericalDeconvolution(
                algorithm=self.fod_algorithm,
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0),
                predicted_signal='predicted.mif'),
            inputs={
                'in_file': (self.series_preproc_spec_name, nifti_gz_format),
                'wm_txt': ('wm_response', text_format),
                'mask_file': (self.brain_mask_spec_name, nifti_gz_format),
                'grad_fsl': self.fsl_grads(pipeline)},
            outputs={
                'wm_odf': ('wm_odf', nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        if self.multi_tissue:
            dwi2fod.inputs.gm_odf = 'gm.mif',
            dwi2fod.inputs.csf_odf = 'csf.mif',
            pipeline.connect_input('gm_response', dwi2fod, 'gm_txt',
                                   text_format),
            pipeline.connect_input('csf_response', dwi2fod, 'csf_txt',
                                   text_format),
            pipeline.connect_output('gm_odf', dwi2fod, 'gm_odf',
                                    nifti_gz_format),
            pipeline.connect_output('csf_odf', dwi2fod, 'csf_odf',
                                    nifti_gz_format),
        # Check inputs/output are connected
        return pipeline

    def extract_b0_pipeline(self, **name_maps):
        """
        Extracts the b0 images from a DWI analysis and takes their mean
        """

        pipeline = self.new_pipeline(
            name='extract_b0',
            desc="Extract b0 image from a DWI analysis",
            citations=[mrtrix_cite],
            name_maps=name_maps)

        # Extraction node
        extract_b0s = pipeline.add(
            'extract_b0s',
            ExtractDWIorB0(
                bzero=True,
                quiet=True),
            inputs={
                'grad_fsl': self.fsl_grads(pipeline),
                'in_file': (self.series_preproc_spec_name, nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        # FIXME: Need a registration step before the mean
        # Mean calculation node
        mean = pipeline.add(
            "mean",
            MRMath(
                axis=3,
                operation='mean',
                quiet=True,
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'in_files': (extract_b0s, 'out_file')},
            requirements=[mrtrix_req.v('3.0rc3')])

        # Convert to Nifti
        pipeline.add(
            "output_conversion",
            MRConvert(
                out_ext='.nii.gz',
                quiet=True),
            inputs={
                'in_file': (mean, 'out_file')},
            outputs={
                'b0': ('out_file', nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        return pipeline

    def global_tracking_pipeline(self, **name_maps):

        pipeline = self.new_pipeline(
            name='global_tracking',
            desc="Extract b0 image from a DWI analysis",
            citations=[mrtrix_cite],
            name_maps=name_maps)

        mask = pipeline.add(
            'mask',
            DWI2Mask(
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'grad_fsl': self.fsl_grads(pipeline),
                'in_file': (self.series_preproc_spec_name, nifti_gz_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        tracking = pipeline.add(
            'tracking',
            Tractography(
                select=self.parameter('num_global_tracks'),
                cutoff=self.parameter('global_tracks_cutoff'),
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'seed_image': (mask, 'out_file'),
                'in_file': ('wm_odf', mrtrix_image_format)},
            outputs={
                'global_tracks': ('out_file', mrtrix_track_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        if self.provided('anat_5tt'):
            pipeline.connect_input('anat_5tt', tracking, 'act_file',
                                   mrtrix_image_format)

        return pipeline

    def intrascan_alignment_pipeline(self, **name_maps):

        pipeline = self.new_pipeline(
            name='affine_mat_generation',
            desc=("Generation of the affine matrices for the main dwi "
                  "sequence starting from eddy motion parameters"),
            citations=[fsl_cite],
            name_maps=name_maps)

        pipeline.add(
            'gen_aff_mats',
            AffineMatrixGeneration(),
            inputs={
                'reference_image': ('mag_preproc', nifti_gz_format),
                'motion_parameters': ('eddy_par', eddy_par_format)},
            outputs={
                'align_mats': ('affine_matrices', motion_mats_format)})

        return pipeline

    def connectome_pipeline(self, **name_maps):

        pipeline = self.new_pipeline(
            name='connectome',
            desc=("Generate a connectome from whole brain connectivity"),
            citations=[],
            name_maps=name_maps)

        aseg_path = pipeline.add(
            'aseg_path',
            AppendPath(
                sub_paths=['mri', 'aparc+aseg.mgz']),
            inputs={
                'base_path': ('anat_fs_recon_all', directory_format)})

        pipeline.add(
            'connectome',
            mrtrix3.BuildConnectome(
                nthreads=(self.processor.cpus_per_task
                          if self.processor.cpus_per_task else 0)),
            inputs={
                'in_file': ('global_tracks', mrtrix_track_format),
                'in_parc': (aseg_path, 'out_path')},
            outputs={
                'connectome': ('out_file', csv_format)},
            requirements=[mrtrix_req.v('3.0rc3')])

        return pipeline


class DwiRefAnalysis(EpiAnalysis, metaclass=AnalysisMetaClass):

    add_data_specs = [
        InputFilesetSpec('reverse_phase', STD_IMAGE_FORMATS, optional=True)
    ]

    desc = ("A special analysis used in the MR-PET motion correction algorithm to"
            " perform distortion correction on the reverse-phase/reference b0 "
            "scans by flipping it around and using the DWI series as the "
            "reference")

    def preprocess_pipeline(self, **name_maps):

        if self.provided('reverse_phase'):
            return self._topup_pipeline(**name_maps)
        else:
            return super().preprocess_pipeline(**name_maps)

    def _topup_pipeline(self, **name_maps):
        """
        Implementation of separate topup pipeline, moved from EPI analysis as it
        is only really relevant for spin-echo DWI. Need to work out what to do
        with it
        """

        pipeline = self.new_pipeline(
            name='preprocess_pipeline',
            desc=("Topup distortion correction pipeline"),
            citations=[fsl_cite],
            name_maps=name_maps)

        reorient_epi_in = pipeline.add(
            'reorient_epi_in',
            fsl.utils.Reorient2Std(),
            inputs={
                'in_file': ('magnitude', nifti_gz_format)},
            requirements=[fsl_req.v('5.0.9')])

        reorient_epi_opposite = pipeline.add(
            'reorient_epi_opposite',
            fsl.utils.Reorient2Std(),
            inputs={
                'in_file': ('reverse_phase', nifti_gz_format)},
            requirements=[fsl_req.v('5.0.9')])

        prep_dwi = pipeline.add(
            'prepare_dwi',
            PrepareDWI(
                topup=True),
            inputs={
                'pe_dir': ('ped', str),
                'ped_polarity': ('pe_angle', str),
                'dwi': (reorient_epi_in, 'out_file'),
                'dwi1': (reorient_epi_opposite, 'out_file')})

        ped = pipeline.add(
            'gen_config',
            GenTopupConfigFiles(),
            inputs={
                'ped': (prep_dwi, 'pe')})

        merge_outputs = pipeline.add(
            'merge_files',
            merge_lists(2),
            inputs={
                'in1': (prep_dwi, 'main'),
                'in2': (prep_dwi, 'secondary')})

        merge = pipeline.add(
            'FslMerge',
            FslMerge(
                dimension='t',
                output_type='NIFTI_GZ'),
            inputs={
                'in_files': (merge_outputs, 'out')},
            requirements=[fsl_req.v('5.0.9')])

        topup = pipeline.add(
            'topup',
            TOPUP(
                output_type='NIFTI_GZ'),
            inputs={
                'in_file': (merge, 'merged_file'),
                'encoding_file': (ped, 'config_file')},
            requirements=[fsl_req.v('5.0.9')])

        in_apply_tp = pipeline.add(
            'in_apply_tp',
            merge_lists(1),
            inputs={
                'in1': (reorient_epi_in, 'out_file')})

        pipeline.add(
            'applytopup',
            ApplyTOPUP(
                method='jac',
                in_index=[1],
                output_type='NIFTI_GZ'),
            inputs={
                'in_files': (in_apply_tp, 'out'),
                'encoding_file': (ped, 'apply_topup_config'),
                'in_topup_movpar': (topup, 'out_movpar'),
                'in_topup_fieldcoef': (topup, 'out_fieldcoef')},
            outputs={
                'mag_preproc': ('out_corrected', nifti_gz_format)},
            requirements=[fsl_req.v('5.0.9')])

        return pipeline
